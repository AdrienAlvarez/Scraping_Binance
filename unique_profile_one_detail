from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import pandas as pd
import time

# URL de la page à scraper
url = "https://www.binance.com/en/futures-activity/leaderboard/top-ranking"

# Configuration du WebDriver
chrome_options = Options()
chrome_options.add_argument("--disable-gpu")
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument("--headless")
driver = webdriver.Chrome(options=chrome_options)

try:
    # Ouvre la page web
    driver.get(url)

    # Attente pour que le contenu de la page se charge
    time.sleep(5)

    # Clique sur le premier élément avec la classe "name css-vurnku"
    element = driver.find_element(By.CLASS_NAME, "name.css-vurnku")
    element.click()

    # Attendez 5 secondes après le clic
    time.sleep(5)

    # Obtention du code source de la page après le clic
    page_source = driver.page_source

    # Utilisation de BeautifulSoup pour analyser le code HTML
    soup = BeautifulSoup(page_source, 'html.parser')

    # Récupération du Nom
    nom = soup.find_all(class_= "name css-1ta711")

    # Récupération des ROIs
    rois = soup.find_all(class_="Number css-rtly53")

    # Assurez-vous qu'il y a 6 valeurs ROI
    if len(rois) == 6:
        data = {
            'Nom': nom,
            'Daily ROI': rois[0].text,
        }
    else:
        data = {'Error': 'Nombre inattendu de valeurs ROI'}

    # Créez un DataFrame à partir des données
    df = pd.DataFrame([data])

    # Affichez le DataFrame
    print(df)

finally:
    # Fermeture du navigateur
    driver.quit()
